# ğŸ“„ RAG Document Ingestion - Instrukcja

## âœ… System zaÅ‚adowany!

TwÃ³j system RAG jest teraz gotowy do pracy z dokumentami w Elasticsearch. ZaindeksowaliÅ›my juÅ¼ **9 chunkÃ³w** z 4 przykÅ‚adowych dokumentÃ³w.

## ğŸ—‚ Jak dodawaÄ‡ dokumenty

### 1. ObsÅ‚ugiwane formaty plikÃ³w

System automatycznie rozpoznaje i przetwarza:

- **ğŸ“„ PDF**: `.pdf` (z uÅ¼yciem iText7)
- **ğŸ“ Word**: `.docx`, `.doc` (DocumentFormat.OpenXml)
- **ğŸ“Š Excel**: `.xlsx`, `.xls` (arkusze kalkulacyjne)
- **ğŸ“‹ Tekstowe**: `.txt`, `.md`, `.csv`

### 2. Lokalizacja dokumentÃ³w

Dodaj pliki do folderu:
```
<project-root>/data/documents/
```

### 3. Automatyczne przetwarzanie

Po dodaniu plikÃ³w uruchom ingestion worker:

```bash
# Na Linux/macOS:
./scripts/ingestion-manager.sh run

# Na Windows:
.\scripts\ingestion-manager.ps1 -Command run

# Albo manualnie:
cd src/RAG.Ingestion.Worker
dotnet run
```

### 4. Sprawdzanie statusu

```bash
# SprawdÅº liczbÄ™ dokumentÃ³w
curl -u elastic:elastic "http://localhost:9200/rag_documents/_count?pretty"

# SprawdÅº przykÅ‚adowy dokument
curl -u elastic:elastic "http://localhost:9200/rag_documents/_search?size=1&pretty"

# Wyszukaj po treÅ›ci
curl -u elastic:elastic -X POST "http://localhost:9200/rag_documents/_search?pretty" \
  -H "Content-Type: application/json" \
  -d '{"query": {"match": {"content": "twoje zapytanie"}}}'
```

## ğŸ”§ Konfiguracja

### Chunk Settings (appsettings.json):
- **ChunkSize**: 1000 znakÃ³w (optymalne dla LLM)
- **ChunkOverlap**: 100 znakÃ³w (zachowanie kontekstu)
- **ProcessOnStartup**: true (automatyczne przetwarzanie)

### Elasticsearch Settings:
- **URL**: http://localhost:9200
- **Credentials**: elastic/elastic
- **Index**: rag_documents

## ğŸ“ Struktura danych

KaÅ¼dy dokument zostaje podzielony na chunki zawierajÄ…ce:

```json
{
  "id": "unique_chunk_id",
  "documentId": "parent_document_id", 
  "fileName": "document.pdf",
  "content": "tekst chunka...",
  "fileType": "PDF",
  "chunkIndex": 0,
  "embedding": [0.123, -0.456, ...], // 768-dim vector
  "createdAt": "2024-08-24T21:06:55Z",
  "metadata": {
    "parser": "PdfDocumentParser",
    "chunkLength": 950
  }
}
```

## ğŸš€ PrzykÅ‚ady uÅ¼ycia

### Dodaj dokumenty PDF/Word:
1. Skopiuj pliki do `/data/documents/`
2. Uruchom: `./scripts/ingestion-manager.sh run`
3. Worker automatycznie przetworzy nowe pliki

### SprawdÅº wyniki wyszukiwania:
```bash
# Test wyszukiwania API
curl -u elastic:elastic -X POST "http://localhost:9200/rag_documents/_search" \
  -H "Content-Type: application/json" \
  -d '{"query": {"match": {"content": "API endpoints"}}}'

# Test wyszukiwania o Elasticsearch
curl -u elastic:elastic -X POST "http://localhost:9200/rag_documents/_search" \
  -H "Content-Type: application/json" \
  -d '{"query": {"match": {"content": "vector search"}}}'
```

## ğŸ¯ Gotowe do produkcji!

TwÃ³j system RAG moÅ¼e teraz:
- âœ… Automatycznie parsowaÄ‡ dokumenty Office i PDF
- âœ… DzieliÄ‡ na optymalne chunki z overlapem
- âœ… GenerowaÄ‡ embeddingi (obecnie mock, do zastÄ…pienia prawdziwym modelem)
- âœ… IndeksowaÄ‡ w Elasticsearch z vector search
- âœ… WyszukiwaÄ‡ dokumenty przez treÅ›Ä‡
- âœ… IntegrowaÄ‡ z Ollama LLM w RAG pipeline

**NastÄ™pny krok**: ZamieÅ„ mock embedding service na prawdziwy model (np. sentence-transformers)!
