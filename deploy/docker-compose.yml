services:

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.11.3
    container_name: es
    environment:
      - node.name=es-node
      - discovery.type=single-node
      - xpack.security.enabled=true
      - ELASTIC_PASSWORD=changeme
      - "ES_JAVA_OPTS=-Xms1g -Xmx1g"
      - "cluster.routing.allocation.disk.threshold_enabled=false"
    ports:
      - "9200:9200"
    volumes:
      - elasticsearch-data:/usr/share/elasticsearch/data
    healthcheck:
      test: ["CMD-SHELL", "curl -s -u elastic:changeme http://localhost:9200/_cluster/health | grep -q '\"status\":\"green\"'"]
      interval: 30s
      timeout: 10s
      retries: 5

  kibana:
    image: docker.elastic.co/kibana/kibana:8.11.3
    container_name: kibana
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
      - ELASTICSEARCH_USERNAME=elastic
      - ELASTICSEARCH_PASSWORD=changeme
    ports:
      - "5601:5601"
    depends_on:
      - elasticsearch

  embedding-service:
    image: ghcr.io/huggingface/text-embeddings-inference:cpu-1.8
    container_name: embedding-service
    volumes:
      - embedding-data:/data
    platform: linux/amd64
    environment:
      - MODEL_ID=sentence-transformers/all-MiniLM-L6-v2
    ports:
      - "8580:80"
    command:
      - --model-id
      - "sentence-transformers/all-MiniLM-L6-v2"
    depends_on:
      - elasticsearch

  llm-service:
    image: ghcr.io/huggingface/text-generation-inference:2.4.0
    container_name: llm-service
    volumes:
      - llm-data:/data
    platform: linux/amd64
    environment:
      - MODEL_ID=gpt2
      - HUGGING_FACE_HUB_TOKEN=${HUGGING_FACE_HUB_TOKEN}
    ports:
      - "8581:80"
    command:
      - --model-id
      - "gpt2"
      - --max-input-length
      - "512"
      - --max-total-tokens
      - "1024"
    depends_on:
      - elasticsearch

  ollama-service:
    image: ollama/ollama:latest
    container_name: ollama-service
    platform: linux/arm64  # Apple Silicon optimized
    environment:
      - OLLAMA_HOST=0.0.0.0:11434
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
    depends_on:
      - elasticsearch
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:11434/api/tags || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 120s

volumes:
  elasticsearch-data:
  ollama_data:
  embedding-data:
  llm-data:
