services:

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.11.3
    container_name: es
    environment:
      - node.name=es-node
      - discovery.type=single-node
      - xpack.security.enabled=true
      - ELASTIC_PASSWORD=changeme
      - "ES_JAVA_OPTS=-Xms1g -Xmx1g"
    ports:
      - "9200:9200"
    healthcheck:
      test: ["CMD-SHELL", "curl -s -u elastic:changeme http://localhost:9200/_cluster/health | grep -q '\"status\":\"green\"'"]
      interval: 30s
      timeout: 10s
      retries: 5

  kibana:
    image: docker.elastic.co/kibana/kibana:8.11.3
    container_name: kibana
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
      - ELASTICSEARCH_USERNAME=elastic
      - ELASTICSEARCH_PASSWORD=changeme
    ports:
      - "5601:5601"
    depends_on:
      - elasticsearch

  embedding-service:
    image: ghcr.io/huggingface/text-embeddings-inference:cpu-1.8
    container_name: embedding-service
    environment:
      - MODEL_ID=intfloat/multilingual-e5-base
    ports:
      - "8580:80"
    command:
      - --model-id
      - "intfloat/multilingual-e5-base"
    depends_on:
      - elasticsearch

  llm-service:
    image: ghcr.io/huggingface/text-generation-inference:2.2.0
    container_name: llm-service
    environment:
      - MODEL_ID=microsoft/DialoGPT-medium
      - HUGGING_FACE_HUB_TOKEN=${HF_TOKEN:-}
      - MAX_TOTAL_TOKENS=4096
      - MAX_INPUT_LENGTH=3072
      - MAX_BATCH_PREFILL_TOKENS=4096
    ports:
      - "8581:80"
    volumes:
      - llm_cache:/data
    command:
      - --model-id
      - "microsoft/DialoGPT-medium"
      - --port
      - "80"
      - --hostname
      - "0.0.0.0"
    depends_on:
      - elasticsearch
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:80/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 120s

volumes:
  llm_cache:
