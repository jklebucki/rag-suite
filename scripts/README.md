# RAG Suite Scripts

## ðŸ˜ PostgreSQL Setup

### Opcja 1: Docker (Zalecane)
```bash
# Uruchom PostgreSQL w kontenerze Docker
./setup-postgres-docker.sh

# ZarzÄ…dzaj kontenerem
./postgres-manager.sh status    # SprawdÅº status
./postgres-manager.sh backup    # UtwÃ³rz backup
./postgres-manager.sh connect   # PoÅ‚Ä…cz siÄ™ z bazÄ…
./postgres-manager.sh help      # Zobacz wszystkie opcje
```

### Opcja 2: Docker Compose
```bash
# Uruchom PostgreSQL z docker-compose
./setup-postgres-compose.sh

# ZarzÄ…dzaj z docker-compose
docker-compose -f scripts/docker-compose.postgres.yml ps
docker-compose -f scripts/docker-compose.postgres.yml logs -f
```

### ðŸ”§ Konfiguracja PostgreSQL:
- **Database:** rag-suite
- **Username:** postgres
- **Password:** postgres
- **Port:** 5432
- **Auto-restart:** Tak (po restarcie serwera)
- **Wolumen:** `/opt/rag-suite/postgresql` (Ubuntu best practices)

## ï¿½ Security Tools

### JWT Key Generation
```bash
# Generuj bezpieczny klucz JWT
./generate-jwt-key.sh

# Dla konkretnego Å›rodowiska
./generate-jwt-key.sh dev
./generate-jwt-key.sh prod
```

## ðŸš€ LLM Integration

```bash
# 1. PrzejdÅº do katalogu scripts
cd scripts

# 2. Uruchom peÅ‚nÄ… konfiguracjÄ™ Å›rodowiska
./rag-manager.sh setup

# 3. (Opcjonalnie) Wybierz konfiguracjÄ™ Å›rodowiska
./rag-manager.sh config

# 4. SprawdÅº status
./rag-manager.sh status

# 5. Uruchom API (w nowym terminalu)
./rag-manager.sh build-api

# 6. Uruchom frontend (w nowym terminalu)
./rag-manager.sh build-ui

# 7. Przetestuj integracjÄ™
./rag-manager.sh test
```

## ðŸ“ DostÄ™pne konfiguracje Å›rodowiska

| Plik | RAM | Model LLM | Przeznaczenie |
|------|-----|-----------|---------------|
| `.env.local` | 4GB | DialoGPT-small | Szybkie testy |
| `.env.development` | 8GB | DialoGPT-medium | Development |
| `.env` | 9GB | DialoGPT-medium | Standard (16GB) |
| `.env.production` | 14GB | DialoGPT-large | Produkcja |

### Zmiana konfiguracji:
```bash
./rag-manager.sh config
```

## ðŸ“ Dodane pliki

### Skrypty zarzÄ…dzania
- `scripts/setup-llm.sh` - Automatyczna instalacja i konfiguracja LLM
- `scripts/test-llm-integration.sh` - Testy integracji miÄ™dzy komponentami
- `scripts/rag-manager.sh` - Uniwersalny manager Å›rodowiska

### Konfiguracja Docker
- `deploy/docker-compose.yml` - Zaktualizowany z kontenerem LLM
- `deploy/docker-compose.prod.yml` - Konfiguracja produkcyjna
- `deploy/.env.template` - Template zmiennych Å›rodowiskowych

### Kod aplikacji
- `src/RAG.Orchestrator.Api/Features/Chat/ChatService.cs` - Zintegrowany z LLM
- `src/RAG.Orchestrator.Api/Features/Chat/ChatEndpoints.cs` - Dodane health checki
- `src/RAG.Orchestrator.Api/Extensions/ServiceCollectionExtensions.cs` - Rejestracja LLM service
- `src/RAG.Orchestrator.Api/appsettings.json` - Konfiguracja LLM

### Dokumentacja
- `docs/LLM-INTEGRATION.md` - SzczegÃ³Å‚owa instrukcja integracji

## ðŸ› ï¸ DostÄ™pne komendy

```bash
./rag-manager.sh [KOMENDA]
```

### Podstawowe operacje
- `setup` - PeÅ‚na instalacja Å›rodowiska
- `start` - Start wszystkich serwisÃ³w
- `stop` - Stop wszystkich serwisÃ³w
- `restart` - Restart wszystkich serwisÃ³w
- `status` - Status serwisÃ³w i health checks

### ZarzÄ…dzanie aplikacjÄ…
- `build-api` - Buduj i uruchom API
- `build-ui` - Buduj i uruchom frontend
- `config` - ZmieÅ„ konfiguracjÄ™ Å›rodowiska

### Diagnostyka
- `test` - Uruchom testy integracji
- `logs` - PokaÅ¼ logi wszystkich serwisÃ³w
- `logs [service]` - Logi konkretnego serwisu
- `monitor` - Monitor zasobÃ³w w czasie rzeczywistym

### Maintenance
- `clean` - WyczyÅ›Ä‡ wszystkie kontenery i volumes

## ðŸ”§ Konfiguracja

### 1. Zmienne Å›rodowiskowe
```bash
# Skopiuj template
cp deploy/.env.template deploy/.env

# Edytuj konfiguracjÄ™
nano deploy/.env
```

### 2. Zmiana modelu LLM
Edytuj `.env`:
```bash
LLM_MODEL_ID=microsoft/DialoGPT-large
MAX_TOTAL_TOKENS=8192
```

### 3. Konfiguracja produkcyjna
```bash
# UÅ¼yj konfiguracji produkcyjnej
cd deploy
docker-compose -f docker-compose.prod.yml up -d
```

## ðŸ“Š Endpointy

### API Chat
- `GET /api/chat/sessions` - Lista sesji
- `POST /api/chat/sessions` - Nowa sesja
- `POST /api/chat/sessions/{id}/messages` - WyÅ›lij wiadomoÅ›Ä‡
- `GET /api/chat/health` - Status LLM

### Health Checks
- `GET /health` - Status API
- `http://localhost:9200/_cluster/health` - Elasticsearch
- `http://localhost:8580/health` - Embedding Service
- `http://localhost:8581/health` - LLM Service

## ðŸŒ DostÄ™p do usÅ‚ug

| Serwis | URL | Dane logowania |
|--------|-----|----------------|
| Orchestrator API | http://localhost:7107 | - |
| Swagger UI | http://localhost:7107 | - |
| Web UI | http://localhost:5173 | - |
| Elasticsearch | http://localhost:9200 | elastic / changeme |
| Kibana | http://localhost:5601 | elastic / changeme |
| LLM Service | http://localhost:8581 | - |
| Embedding Service | http://localhost:8580 | - |

## ðŸ§ª Testowanie

### Test podstawowy
```bash
# SprawdÅº wszystkie serwisy
curl http://localhost:7107/health

# Test LLM bezpoÅ›rednio
curl -X POST http://localhost:8581/generate \
  -H "Content-Type: application/json" \
  -d '{"inputs": "CzeÅ›Ä‡!", "parameters": {"max_new_tokens": 50}}'
```

### Test chat API
```bash
# UtwÃ³rz sesjÄ™
SESSION_ID=$(curl -s -X POST http://localhost:7107/api/chat/sessions \
  -H "Content-Type: application/json" \
  -d '{"title": "Test"}' | jq -r '.data.id')

# WyÅ›lij wiadomoÅ›Ä‡
curl -X POST "http://localhost:7107/api/chat/sessions/$SESSION_ID/messages" \
  -H "Content-Type: application/json" \
  -d '{"message": "Jak dziaÅ‚ajÄ… bazy danych Oracle?"}'
```

## ðŸ” Troubleshooting

### LLM Service nie startuje
```bash
# SprawdÅº logi
docker-compose logs llm-service

# SprawdÅº miejsce na dysku
df -h

# Restart z czasem na pobranie modelu
docker-compose restart llm-service
```

### Brak pamiÄ™ci
```bash
# ZwiÄ™ksz limity Docker Desktop do 8GB+
# Lub uÅ¼yj mniejszego modelu w .env:
LLM_MODEL_ID=microsoft/DialoGPT-small
```

### API nie Å‚Ä…czy siÄ™ z LLM
```bash
# SprawdÅº status wszystkich serwisÃ³w
./rag-manager.sh status

# SprawdÅº health check LLM
curl http://localhost:8581/health
```

## ðŸ”„ Integracja z frontendem

PrzykÅ‚ad JavaScript/TypeScript:
```typescript
// PoÅ‚Ä…czenie z chat API
const sendMessage = async (sessionId: string, message: string) => {
  const response = await fetch(`/api/chat/sessions/${sessionId}/messages`, {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({ message })
  });
  return await response.json();
};

// Sprawdzenie statusu LLM
const checkLlmHealth = async () => {
  const response = await fetch('/api/chat/health');
  return await response.json();
};
```

## ðŸ“ˆ Monitoring

### Logs
```bash
# Wszystkie logi
./rag-manager.sh logs

# Konkretny serwis
./rag-manager.sh logs llm-service

# Monitor w czasie rzeczywistym
./rag-manager.sh monitor
```

### Metryki
- Kibana Dashboard: http://localhost:5601
- Resource Monitor: `./rag-manager.sh monitor`
- Docker Stats: `docker stats`

## ðŸš€ Deployment na produkcjÄ™

1. **UÅ¼yj docker-compose.prod.yml**:
```bash
cd deploy
docker-compose -f docker-compose.prod.yml up -d
```

2. **Konfiguruj bezpieczeÅ„stwo**:
- ZmieÅ„ hasÅ‚a w `.env`
- WÅ‚Ä…cz HTTPS
- Skonfiguruj firewall

3. **Skaaluj zasoby**:
- ZwiÄ™ksz pamiÄ™Ä‡ dla Elasticsearch
- UÅ¼yj wiÄ™kszego modelu LLM
- Dodaj load balancer

---

## âœ… Co zostaÅ‚o dodane

âœ… Kontener LLM (Text Generation Inference)  
âœ… Integracja z ChatService  
âœ… Automatyczne skrypty instalacji  
âœ… Testy integracji  
âœ… Health checks  
âœ… Monitoring  
âœ… Dokumentacja  
âœ… Konfiguracja produkcyjna  
âœ… Manager Å›rodowiska  

**Projekt RAG Suite jest teraz w peÅ‚ni zintegrowany z LLM! ðŸŽ‰**
